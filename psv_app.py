
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

import matplotlib as mpl
from matplotlib import font_manager

# ================== æ•°æ®å­˜å‚¨ï¼šSupabaseï¼ˆå¤šäººå…±äº«ï¼‰ ==================
# è¯´æ˜ï¼šä¸æ”¹å˜ä½ é¡¹ç›®ä»»ä½•ä¸šåŠ¡é€»è¾‘ï¼ŒåªæŠŠâ€œæœ¬åœ°CSVâ€æ›¿æ¢ä¸ºâ€œSupabaseäº‘æ•°æ®åº“â€ã€‚
# å»ºè®®æŠŠå¯†é’¥æ”¾åœ¨ Streamlit Secrets æˆ–ç¯å¢ƒå˜é‡é‡Œï¼Œé¿å…å†™è¿›ä»£ç ã€‚

try:
    from supabase import create_client
    SUPABASE_OK = True
except Exception:
    SUPABASE_OK = False

# ä¼˜å…ˆä» st.secrets è¯»å–ï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
SUPABASE_URL = None
SUPABASE_KEY = None
try:
    SUPABASE_URL = st.secrets.get("SUPABASE_URL", None)
    SUPABASE_KEY = st.secrets.get("SUPABASE_KEY", None)
except Exception:
    pass

SUPABASE_URL = SUPABASE_URL or os.getenv("SUPABASE_URL", "")
SUPABASE_KEY = SUPABASE_KEY or os.getenv("SUPABASE_KEY", "")

# ä½ å¯ä»¥æŠŠ USE_SUPABASE è®¾ä¸º True å¼ºåˆ¶ä½¿ç”¨äº‘ç«¯ï¼›å¦‚æœå¯†é’¥ç¼ºå¤±ä¼šè‡ªåŠ¨å›é€€æœ¬åœ°CSVï¼ˆä¾¿äºä½ æœ¬åœ°è°ƒè¯•ï¼‰
USE_SUPABASE = True
supabase = None
if USE_SUPABASE and SUPABASE_OK and SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
elif USE_SUPABASE:
    # å¯†é’¥ç¼ºå¤±æ—¶æç¤ºä¸€æ¬¡ï¼Œä½†ä»å…è®¸å›é€€æœ¬åœ°CSVä»¥å…ç¨‹åºç›´æ¥æŒ‚æ‰
    st.sidebar.warning("âš ï¸ æœªæ£€æµ‹åˆ° Supabase é…ç½®ï¼ˆSUPABASE_URL / SUPABASE_KEYï¼‰ï¼Œå°†å›é€€ä¸ºæœ¬åœ°CSVå­˜å‚¨ã€‚")
    USE_SUPABASE = False

# =====================================================================


# ================== æœºå™¨å­¦ä¹ ï¼šIsolation Forestï¼ˆæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼‰ ==================
try:
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler
    SKLEARN_OK = True
except Exception:
    SKLEARN_OK = False


# ================== Matplotlib ä¸­æ–‡å­—ä½“ä¿®å¤ï¼ˆé¿å…å›¾è¡¨æ ‡é¢˜/æ ‡ç­¾ä¹±ç ï¼‰ ==================
def _setup_cjk_font():
    # ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­å¸¸è§çš„ä¸­æ–‡å­—ä½“ï¼›åœ¨å¤šæ•° Linux ç¯å¢ƒä¸‹ NotoSansCJK å¯ç”¨
    preferred_font_names = [
        "Noto Sans CJK SC",
        "Noto Sans CJK JP",
        "Noto Sans CJK TC",
        "Microsoft YaHei",
        "SimHei",
        "PingFang SC",
        "WenQuanYi Micro Hei",
        "Source Han Sans SC",
    ]

    available = {f.name for f in font_manager.fontManager.ttflist}
    for name in preferred_font_names:
        if name in available:
            mpl.rcParams["font.family"] = "sans-serif"
            mpl.rcParams["font.sans-serif"] = [name, "DejaVu Sans"]
            mpl.rcParams["axes.unicode_minus"] = False
            return

    # å…œåº•ï¼šç›´æ¥æŒ‡å®š NotoSansCJK å­—ä½“æ–‡ä»¶ï¼ˆå®¹å™¨é‡Œé€šå¸¸æœ‰ï¼‰
    font_path = "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc"
    if os.path.exists(font_path):
        fp = font_manager.FontProperties(fname=font_path)
        mpl.rcParams["font.family"] = fp.get_name()
        mpl.rcParams["axes.unicode_minus"] = False

_setup_cjk_font()

# ================== é…ç½®åŒº ==================
SET_P = 1.32  # å®‰å…¨é˜€æ•´å®šå‹åŠ›ï¼ˆMPaï¼‰
DATA_FILE = "psv_data.csv"
APP_PASSWORD = "adsf0608"  # ç®€å•å£ä»¤ï¼ˆå¯åç»­æ¢æˆè´¦å·ä½“ç³»ï¼‰

st.set_page_config(page_title="LNGå®‰å…¨é˜€å¥åº·ç›‘æµ‹ç³»ç»Ÿ", layout="wide")

# ================== ç™»å½• ==================
st.sidebar.title("ğŸ” è®¿é—®æ§åˆ¶")
user_password = st.sidebar.text_input("è¯·è¾“å…¥å¯†ç ", type="password")
if user_password != APP_PASSWORD:
    st.warning("è¯·è¾“å…¥æ­£ç¡®å¯†ç åè¿›å…¥ç³»ç»Ÿ å½“å‰ç‰ˆæœ¬v0.2 å¼€å‘ï¼šYXYã€‚")
    st.stop()


# ================== AI è®¾ç½®ï¼ˆæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼‰ ==================
st.sidebar.divider()
st.sidebar.header("ğŸ§  AI å¼‚å¸¸æ£€æµ‹ï¼ˆIsolation Forestï¼‰")
enable_ai = st.sidebar.checkbox("å¯ç”¨ AI å¼‚å¸¸æ£€æµ‹", value=True)
contamination = st.sidebar.slider("å¼‚å¸¸æ¯”ä¾‹ï¼ˆè¶Šå¤§è¶Šæ•æ„Ÿï¼‰", min_value=0.02, max_value=0.20, value=0.08, step=0.01)

if enable_ai and not SKLEARN_OK:
    st.sidebar.warning("å½“å‰ç¯å¢ƒç¼ºå°‘ scikit-learnï¼ŒAI å¼‚å¸¸æ£€æµ‹ä¸å¯ç”¨ã€‚å¯æ‰§è¡Œï¼špip install scikit-learn")
    enable_ai = False

# ================== æ ‡é¢˜ ==================
st.title("ç‰æºªé”€å”®åŠ æ°”ç«™ LNG å®‰å…¨é˜€ AI å¥åº·ç›‘æµ‹ä¸å¼‚å¸¸è¯†åˆ«ç³»ç»Ÿ")
st.caption("åŸºäºæ¯æ—¥äººå·¥ä¸ŠæŠ¥æ•°æ®çš„é£é™©é¢„è­¦ã€è¶‹åŠ¿åˆ†æä¸æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆIsolation Forestï¼‰ï¼ˆæ•´å®šå‹åŠ›ï¼š1.32 MPaï¼‰")

# ================== åˆå§‹åŒ–æ•°æ®æ–‡ä»¶/äº‘ç«¯è¡¨ ==================
# ä½ åŸå…ˆç”¨ CSV å­˜å‚¨ï¼›è¿™é‡Œä¿æŒ CSV é€»è¾‘ä¸åˆ ï¼Œåªæ˜¯åœ¨ USE_SUPABASE=True ä¸”é…ç½®é½å…¨æ—¶æ”¹ç”¨ Supabase è¡¨ï¼špsv_data
if not USE_SUPABASE:
    if not os.path.exists(DATA_FILE):
        df_init = pd.DataFrame(
            columns=["date", "valve_type", "p_now", "p_max", "level", "temp", "psv_act", "psv_weeping"]
        )
        df_init.to_csv(DATA_FILE, index=False, encoding="utf-8-sig")

def load_data() -> pd.DataFrame:
    # ---- äº‘ç«¯ï¼šSupabase ----
    if USE_SUPABASE and supabase is not None:
        resp = supabase.table("psv_data").select("*").execute()
        data = resp.data or []
        df0 = pd.DataFrame(data)
        if len(df0) == 0:
            return df0
        # Supabase è¿”å›çš„ date å¯èƒ½æ˜¯å­—ç¬¦ä¸²
        df0["date"] = pd.to_datetime(df0["date"]).dt.date
        # å…œåº•ï¼šé˜²æ­¢å­—ç¬¦ä¸²/ç©ºå€¼
        for col in ["p_now", "p_max", "level", "temp", "psv_act", "psv_weeping"]:
            if col in df0.columns:
                df0[col] = pd.to_numeric(df0[col], errors="coerce")
        df0 = df0.dropna(subset=["date", "valve_type", "p_max"])
        return _normalize_df(df0)

    # ---- æœ¬åœ°ï¼šCSVï¼ˆå›é€€ï¼‰----
    df0 = pd.read_csv(DATA_FILE)
    if len(df0) == 0:
        return df0
    df0["date"] = pd.to_datetime(df0["date"]).dt.date
    # å…œåº•ï¼šé˜²æ­¢å­—ç¬¦ä¸²/ç©ºå€¼
    for col in ["p_now", "p_max", "level", "temp", "psv_act", "psv_weeping"]:
        if col in df0.columns:
            df0[col] = pd.to_numeric(df0[col], errors="coerce")
    df0 = df0.dropna(subset=["date", "valve_type", "p_max"])
    return _normalize_df(df0)




def _normalize_df(df0: pd.DataFrame) -> pd.DataFrame:
    """ç»Ÿä¸€åšæ•°æ®æ¸…æ´—/çº¦æŸï¼Œé¿å…å½•å…¥æˆ–å­˜å‚¨å¯¼è‡´çš„å›¾è¡¨å¼‚å¸¸ã€‚"""
    if df0 is None or len(df0) == 0:
        return df0

    df = df0.copy()

    # ç±»å‹å…œåº•
    df["date"] = pd.to_datetime(df["date"]).dt.date
    for col in ["p_now", "p_max", "level", "temp", "psv_act", "psv_weeping"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # åˆç†èŒƒå›´ï¼ˆé˜²æ­¢è¯¯å½•ï¼‰
    if "p_now" in df.columns:
        df["p_now"] = df["p_now"].clip(lower=0, upper=2)
    if "p_max" in df.columns:
        df["p_max"] = df["p_max"].clip(lower=0, upper=2)
    if "level" in df.columns:
        df["level"] = df["level"].clip(lower=0, upper=100)
    if "temp" in df.columns:
        df["temp"] = df["temp"].clip(lower=-50, upper=80)

    # ç‰©ç†çº¦æŸï¼šå½“æ—¥æœ€é«˜å‹åŠ› >= å½“å‰å‹åŠ›ï¼ˆè‹¥è¿åï¼ŒæŒ‰ p_now ä¿®æ­£ p_maxï¼‰
    if "p_now" in df.columns and "p_max" in df.columns:
        m = df["p_max"].notna() & df["p_now"].notna() & (df["p_max"] < df["p_now"])
        if m.any():
            df.loc[m, "p_max"] = df.loc[m, "p_now"]

    # åŒä¸€é˜€é—¨åŒä¸€å¤©é‡å¤å½•å…¥ï¼šä¿ç•™æœ€åä¸€æ¡ï¼ˆé¿å…å›¾è¡¨â€œçœ‹èµ·æ¥ä¸å¯¹â€ï¼‰
    if set(["date", "valve_type"]).issubset(df.columns):
        df = df.sort_values(["valve_type", "date"]).drop_duplicates(
            subset=["date", "valve_type"], keep="last"
        )

    df = df.dropna(subset=["date", "valve_type", "p_max"])
    return df
def compute_scores(df0: pd.DataFrame, enable_ai: bool, contamination: float) -> pd.DataFrame:
    if df0 is None or len(df0) == 0:
        return df0

    df0 = _normalize_df(df0)
    if df0 is None or len(df0) == 0:
        return df0

    df = df0.copy()
    df = df.sort_values(["valve_type", "date"]).reset_index(drop=True)

    # ratioï¼šå½“æ—¥æœ€é«˜å‹åŠ›æ¥è¿‘æ•´å®šå‹åŠ›çš„ç¨‹åº¦
    df["ratio"] = df["p_max"] / SET_P

    # slopeï¼š3æ—¥å‹åŠ›å˜åŒ–è¶‹åŠ¿ï¼ˆæŒ‰é˜€é—¨åˆ†ç»„ï¼‰
    df["slope"] = (
        df.groupby("valve_type")["p_max"]
        .apply(lambda s: s.diff().rolling(3).mean())
        .reset_index(level=0, drop=True)
    )

    HI = np.full(len(df), 100.0)

    # A) æ¥è¿‘æ•´å®šå‹åŠ›æ‰£åˆ†ï¼ˆåˆ†æ®µï¼‰
    HI -= np.where(df["ratio"] >= 1.00, 35, 0)
    HI -= np.where((df["ratio"] >= 0.98) & (df["ratio"] < 1.00), 20, 0)
    HI -= np.where((df["ratio"] >= 0.95) & (df["ratio"] < 0.98), 10, 0)

    # B) è¿ç»­ä¸Šå‡è¶‹åŠ¿æ‰£åˆ†ï¼ˆ3æ—¥å‡å€¼ï¼‰
    HI -= np.where(df["slope"] > 0.01, 10, 0)   # 3å¤©å¹³å‡æ¯å¤© +0.01MPa
    HI -= np.where(df["slope"] > 0.02, 10, 0)   # æ›´é™¡å†æ‰£ä¸€æ¬¡

    # C) åŠ¨ä½œ/å¾®æ”¾æ•£æ‰£åˆ†ï¼ˆç»´æŠ¤è§¦å‘ä¿¡å·ï¼‰
    HI -= df.get("psv_act", 0).fillna(0) * 30
    HI -= df.get("psv_weeping", 0).fillna(0) * 15

    # D) é«˜æ¸© + é«˜æ¶²ä½ + é«˜å‹åŠ›ï¼ˆé£é™©å åŠ å› å­ï¼‰
    HI -= np.where(
        (df.get("temp", 0).fillna(0) >= 33)
        & (df.get("level", 0).fillna(0) >= 80)
        & (df["ratio"] >= 0.95),
        10,
        0,
    )

    df["HI"] = np.clip(HI, 0, 100)

    def risk(x: float) -> str:
        if x >= 85:
            return "ğŸŸ¢ å®‰å…¨"
        if x >= 70:
            return "ğŸŸ¡ é¢„è­¦"
        return "ğŸ”´ é«˜é£é™©"

    df["Risk"] = df["HI"].apply(risk)
    df["Activity"] = df.get("psv_act", 0).fillna(0) + df.get("psv_weeping", 0).fillna(0)



    # ================== AI å¼‚å¸¸æ£€æµ‹ï¼ˆIsolation Forestï¼‰ ==================
    # è¯´æ˜ï¼šæ— ç›‘ç£ç®—æ³•ï¼Œä¸éœ€è¦æ•…éšœæ ‡ç­¾ï¼›ç”¨äºå‘ç°â€œæ¨¡å¼å¼‚å¸¸â€çš„è¿è¡Œæ—¥ï¼Œè¡¥è¶³è§„åˆ™é˜ˆå€¼çš„ç›²åŒºã€‚
    df["AI_anomaly"] = False
    df["AI_score"] = np.nan

    if enable_ai and SKLEARN_OK:
        features = ["p_now", "p_max", "level", "temp", "ratio", "slope", "Activity"]
        for valve, g in df.groupby("valve_type"):
            idx = g.index
            # æ•°æ®å¤ªå°‘æ—¶ä¸åšAIï¼ˆé¿å…è¯¯æŠ¥ï¼‰
            if len(g) < 10:
                continue

            X = g[features].copy()
            # ç¼ºå¤±å€¼ç”¨è¯¥é˜€é—¨çš„ä¸­ä½æ•°å¡«å……
            X = X.apply(pd.to_numeric, errors="coerce")
            X = X.fillna(X.median(numeric_only=True))

            scaler = StandardScaler()
            Xs = scaler.fit_transform(X.values)

            iso = IsolationForest(
                n_estimators=200,
                contamination=float(contamination),
                random_state=42,
            )
            iso.fit(Xs)

            pred = iso.predict(Xs)  # -1=å¼‚å¸¸, 1=æ­£å¸¸
            score = -iso.score_samples(Xs)  # å€¼è¶Šå¤§è¶Šâ€œå¼‚å¸¸â€

            df.loc[idx, "AI_anomaly"] = (pred == -1)
            df.loc[idx, "AI_score"] = score

        # å°†AIå¼‚å¸¸ä½œä¸ºâ€œé¢å¤–é£é™©å› å­â€èåˆåˆ°å¥åº·æŒ‡æ•°ä¸­ï¼ˆè½»é‡èåˆï¼Œé¿å…è¿‡åº¦å½±å“ï¼‰
        df["HI_final"] = np.clip(df["HI"] - df["AI_anomaly"].astype(int) * 10, 0, 100)
    else:
        df["HI_final"] = df["HI"]

    df["Risk_final"] = df["HI_final"].apply(risk)

    return df

df_raw = load_data()

# ================== ä¾§è¾¹æ ï¼šå½•å…¥ ==================
st.sidebar.divider()
st.sidebar.header("ğŸ“ æ¯æ—¥æ•°æ®å½•å…¥")

valve_type = st.sidebar.selectbox("é€‰æ‹©å®‰å…¨é˜€ç±»å‹", ["æ³µåå®‰å…¨é˜€", "å‚¨ç½ä¸»é˜€", "å‚¨ç½è¾…é˜€"])
date = st.sidebar.date_input("æ—¥æœŸ")
p_now = st.sidebar.number_input("å½“å‰å‹åŠ› p_now (MPa)", 0.0, 2.0, 1.20, 0.01)
p_max = st.sidebar.number_input("å½“æ—¥æœ€é«˜å‹åŠ› p_max (MPa)", 0.0, 2.0, 1.20, 0.01, help="å»ºè®®ï¼šp_max â‰¥ p_nowï¼›è‹¥è¾“å…¥å°äº p_nowï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŒ‰ p_now ä¿®æ­£ã€‚")
level = st.sidebar.number_input("æ¶²ä½ level (%)", 0, 100, 60)
temp = st.sidebar.number_input("ç¯å¢ƒæ¸©åº¦ temp (â„ƒ)", -30, 60, 25)
psv_act = st.sidebar.selectbox("æ˜¯å¦åŠ¨ä½œ", ["å¦", "æ˜¯"])
psv_weeping = st.sidebar.selectbox("æ˜¯å¦å¾®æ”¾æ•£/å˜¶å˜¶å£°", ["å¦", "æ˜¯"])

if st.sidebar.button("ä¿å­˜å¹¶è®¡ç®—", use_container_width=True):
    # æ•°æ®æ ¡éªŒï¼šå½“æ—¥æœ€é«˜å‹åŠ›åº” >= å½“å‰å‹åŠ›
    p_now_f = float(p_now)
    p_max_f = float(p_max)
    if p_max_f < p_now_f:
        st.sidebar.warning(f"å·²è‡ªåŠ¨ä¿®æ­£ï¼šp_max({p_max_f:.2f}) < p_now({p_now_f:.2f})ï¼Œå°† p_max è®¾ä¸º {p_now_f:.2f}")
        p_max_f = p_now_f

    # ä½ åŸæ¥çš„å½•å…¥å­—æ®µä¸é€»è¾‘ä¿æŒä¸å˜ï¼Œåªæ›¿æ¢â€œä¿å­˜ä½ç½®â€
    if USE_SUPABASE and supabase is not None:
        supabase.table("psv_data").upsert(
            {
                "date": str(date),
                "valve_type": valve_type,
                "p_now": p_now_f,
                "p_max": p_max_f,
                "level": int(level),
                "temp": int(temp),
                "psv_act": 1 if psv_act == "æ˜¯" else 0,
                "psv_weeping": 1 if psv_weeping == "æ˜¯" else 0,
            },
            on_conflict="date,valve_type",
        ).execute()
        st.sidebar.success("âœ… æ•°æ®å·²ä¿å­˜åˆ° Supabaseï¼ˆäº‘ç«¯ï¼‰")
        st.rerun()
    else:
        new_row = pd.DataFrame(
            [{
                "date": date,
                "valve_type": valve_type,
                "p_now": p_now_f,
                "p_max": p_max_f,
                "level": level,
                "temp": temp,
                "psv_act": 1 if psv_act == "æ˜¯" else 0,
                "psv_weeping": 1 if psv_weeping == "æ˜¯" else 0,
            }]
        )

        df_to_save = pd.concat([df_raw, new_row], ignore_index=True)
        # åŒä¸€é˜€é—¨åŒä¸€å¤©é‡å¤å½•å…¥ï¼šä¿ç•™æœ€åä¸€æ¡
        df_to_save = df_to_save.sort_values(['valve_type','date']).drop_duplicates(subset=['date','valve_type'], keep='last')
        df_to_save.to_csv(DATA_FILE, index=False, encoding="utf-8-sig")
        st.sidebar.success("âœ… æ•°æ®å·²ä¿å­˜ï¼ˆåˆ·æ–°é¡µé¢å¯çœ‹åˆ°æ›´æ–°ï¼‰")

# é‡æ–°åŠ è½½ + è®¡ç®—
df_raw = load_data()
df = compute_scores(df_raw, enable_ai=enable_ai, contamination=contamination)

# ================== ä¸»é¡µé¢ ==================
if len(df) == 0:
    st.info("å½“å‰è¿˜æ²¡æœ‰æ•°æ®ï¼šè¯·åœ¨å·¦ä¾§å½•å…¥å¹¶ç‚¹å‡»ã€ä¿å­˜å¹¶è®¡ç®—ã€‘ã€‚")
    st.stop()

# æ—¥æœŸèŒƒå›´ç­›é€‰ï¼ˆé¢†å¯¼å±•ç¤ºä¼šæ›´åƒâ€œç³»ç»Ÿâ€ï¼‰
min_d, max_d = df["date"].min(), df["date"].max()
colA, colB, colC = st.columns([1, 1, 2])
with colA:
    start_date = st.date_input("å¼€å§‹æ—¥æœŸ", value=min_d, min_value=min_d, max_value=max_d, key="start_date")
with colB:
    end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=max_d, min_value=min_d, max_value=max_d, key="end_date")
with colC:
    st.caption("æç¤ºï¼šå¦‚æœæ•°æ®é‡å°ï¼Œå»ºè®®å…ˆå½•å…¥ 10â€“30 å¤©")

df_f = df[(df["date"] >= start_date) & (df["date"] <= end_date)].copy()
if len(df_f) == 0:
    st.warning("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®ã€‚")
    st.stop()

with st.expander("ğŸ“¥ å¯¼å‡ºæ•°æ®ï¼ˆæ‰€é€‰æ—¥æœŸèŒƒå›´ï¼‰", expanded=False):
    csv_bytes = df_f.sort_values(["valve_type", "date"]).to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    st.download_button(
        label="ä¸‹è½½ CSV",
        data=csv_bytes,
        file_name="psv_data_filtered.csv",
        mime="text/csv",
        use_container_width=True,
    )

# ============ æ€»è§ˆçœ‹æ¿ ============
st.subheader("ğŸ“Œ æ€»è§ˆçœ‹æ¿ï¼ˆæœ€æ–°çŠ¶æ€ï¼‰")

latest_by_valve = df.sort_values(["valve_type", "date"]).groupby("valve_type").tail(1)
cols = st.columns(3)
for i, valve in enumerate(["æ³µåå®‰å…¨é˜€", "å‚¨ç½ä¸»é˜€", "å‚¨ç½è¾…é˜€"]):
    block = latest_by_valve[latest_by_valve["valve_type"] == valve]
    if len(block) == 0:
        cols[i].metric(f"{valve} å½“å‰å¥åº·æŒ‡æ•°", "â€”")
        cols[i].metric(f"{valve} é£é™©ç­‰çº§", "â€”")
        continue
    row = block.iloc[0]
    cols[i].metric(f"{valve} å½“å‰å¥åº·æŒ‡æ•°", f"{row['HI_final']:.1f}")
    cols[i].metric(f"{valve} é£é™©ç­‰çº§", row["Risk_final"])
    cols[i].caption(f"æœ€é«˜å‹åŠ›å æ•´å®šæ¯”ä¾‹ï¼š{row['ratio'] * 100:.1f}% ï½œ åŠ¨ä½œ:{int(row.get('psv_act',0))} å¾®æ”¾æ•£:{int(row.get('psv_weeping',0))}")

st.divider()

# ============ è¯¦æƒ…ï¼šæŒ‰é˜€é—¨è¶‹åŠ¿ ============
st.subheader("ğŸ“ˆ å•é˜€è¶‹åŠ¿ï¼ˆå‹åŠ› & å¥åº·æŒ‡æ•°ï¼‰")
valve_pick = st.selectbox("é€‰æ‹©æŸ¥çœ‹çš„é˜€é—¨", sorted(df_f["valve_type"].unique()), index=0)

vdf = df_f[df_f["valve_type"] == valve_pick].sort_values("date").copy()
vdf["date_dt"] = pd.to_datetime(vdf["date"])

c1, c2 = st.columns(2)
with c1:
    fig, ax = plt.subplots()
    ax.plot(vdf["date_dt"], vdf["p_max"], marker="o", label="p_max")
    if "p_now" in vdf.columns:
        ax.plot(vdf["date_dt"], vdf["p_now"], marker="o", linestyle="--", label="p_now")
    ax.axhline(SET_P, linestyle="--", label="æ•´å®šå‹åŠ› 1.32MPa")
    ax.set_title(f"{valve_pick}ï¼šå½“æ—¥æœ€é«˜å‹åŠ›è¶‹åŠ¿")
    ax.set_ylabel("MPa")
    ax.set_xlabel("æ—¥æœŸ")
    ax.legend()
    ax.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    plt.xticks(rotation=30)
    st.pyplot(fig)

with c2:
    fig, ax = plt.subplots()
    ax.plot(vdf["date_dt"], vdf["HI_final"], marker="o")
    ax.set_title(f"{valve_pick}ï¼šå¥åº·æŒ‡æ•°è¶‹åŠ¿ï¼ˆHIï¼ŒAIèåˆï¼‰")
    ax.set_ylabel("HI (0-100)")
    ax.set_xlabel("æ—¥æœŸ")
    ax.set_ylim(0, 100)
    ax.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    plt.xticks(rotation=30)
    st.pyplot(fig)

st.divider()

# ============ é«˜çº§å¯è§†åŒ– ============
st.subheader("ğŸ§  é«˜çº§å¯è§†åŒ–")
st.caption("å»ºè®®é˜…è¯»é¡ºåºï¼šâ‘ çƒ­åŠ›å›¾æ‰¾â€œå“ªå¤©å“ªé˜€å˜å·®â€ â†’ â‘¡å¯¹æ¯”å›¾å†³å®šâ€œä¼˜å…ˆå¤„ç†å“ªåªé˜€â€ â†’ â‘¢ç›¸å…³å›¾è§£é‡Šâ€œå‹åŠ›æ¥è¿‘æ•´å®šæ˜¯å¦æ›´å®¹æ˜“åŠ¨ä½œ/å¾®æ”¾æ•£â€ã€‚")

g1, g2, g3 = st.columns(3, gap="small")

# ---- 1) çƒ­åŠ›å›¾ï¼šå¥åº·éšæ—¶é—´ï¼ˆå°å›¾ï¼‰----
with g1:
    st.markdown("**â‘  çƒ­åŠ›å›¾ï¼šå¥åº·éšæ—¶é—´**")
    st.caption("é¢œè‰²è¶Šæ·±ï¼ˆåç´«ï¼‰ä»£è¡¨ HI è¶Šä½ã€‚")

    heat = df_f.pivot_table(index="valve_type", columns="date", values="HI_final", aggfunc="mean")
    fig, ax = plt.subplots(figsize=(4.2, 3.2))
    im = ax.imshow(heat.values, aspect="auto")
    ax.set_title("HI çƒ­åŠ›å›¾")

    ax.set_yticks(range(len(heat.index)))
    ax.set_yticklabels(list(heat.index))

    # æ—¥æœŸå¤ªå¤šæ—¶åšæŠ½æ ·ï¼Œé¿å…å°å›¾æŒ¤çˆ†
    cols = list(heat.columns)
    if len(cols) <= 10:
        tick_idx = list(range(len(cols)))
    else:
        tick_idx = sorted(set(np.linspace(0, len(cols) - 1, 8).round().astype(int).tolist()))
    ax.set_xticks(tick_idx)
    ax.set_xticklabels([pd.to_datetime(cols[i]).strftime("%m-%d") for i in tick_idx], rotation=45, ha="right")

    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04, label="HI")
    fig.tight_layout()
    st.pyplot(fig, use_container_width=True)

# ---- 2) æ¡å½¢å›¾ï¼šé˜€é—¨å¯¹æ¯”ï¼ˆå°å›¾ï¼‰----
with g2:
    st.markdown("**â‘¡ å¯¹æ¯”ï¼šå¹³å‡HI & é¢„è­¦å¤©æ•°**")
    st.caption("å¹³å‡HIè¶Šä½ã€çº¢/é»„å¤©æ•°è¶Šå¤š â†’ è¶Šä¼˜å…ˆå¤„ç†ã€‚")

    summary = (
        df_f.groupby("valve_type")
        .agg(
            avg_HI=("HI_final", "mean"),
            min_HI=("HI_final", "min"),
            red_days=("Risk_final", lambda s: (s == "ğŸ”´ é«˜é£é™©").sum()),
            yellow_days=("Risk_final", lambda s: (s == "ğŸŸ¡ é¢„è­¦").sum()),
            act_cnt=("psv_act", "sum"),
            weep_cnt=("psv_weeping", "sum"),
        )
        .reset_index()
        .sort_values("avg_HI", ascending=False)
    )

    fig, ax = plt.subplots(figsize=(4.2, 3.2))
    ax.bar(summary["valve_type"], summary["avg_HI"])
    ax.set_title("å¹³å‡HIï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰")
    ax.set_ylabel("avg HI")
    ax.set_ylim(0, 100)
    plt.xticks(rotation=20, ha="right")
    fig.tight_layout()
    st.pyplot(fig, use_container_width=True)

    # å°å›¾ä¸‹æ–¹ç»™ä¸€è¡Œâ€œç»“è®ºæç¤ºâ€ï¼Œé¢†å¯¼æ›´å®¹æ˜“çœ‹æ‡‚
    worst = summary.sort_values("avg_HI").head(1).iloc[0]
    st.info(f"ä¼˜å…ˆå…³æ³¨ï¼š{worst['valve_type']}ï¼ˆå¹³å‡HIâ‰ˆ{worst['avg_HI']:.1f}ï¼Œé«˜é£é™©å¤©æ•°={int(worst['red_days'])}ï¼Œé¢„è­¦å¤©æ•°={int(worst['yellow_days'])}ï¼‰")

# ---- 3) æ•£ç‚¹å›¾ï¼šå‹åŠ› vs æ´»åŠ¨ï¼ˆå°å›¾ï¼‰----
with g3:
    st.markdown("**â‘¢ ç›¸å…³ï¼šå‹åŠ› vs åŠ¨ä½œ/å¾®æ”¾æ•£**")
    st.caption("ç‚¹è¶Šé ä¸Šä»£è¡¨åŠ¨ä½œ/å¾®æ”¾æ•£è¶Šå¤šï¼›ç”¨äºéªŒè¯é˜ˆå€¼è®¾ç½®æ˜¯å¦åˆç†ã€‚")

    sdf = df_f.copy()
    jitter = (np.random.default_rng(0).random(len(sdf)) - 0.5) * 0.06
    y = sdf["Activity"].values + jitter

    fig, ax = plt.subplots(figsize=(4.2, 3.2))
    ax.scatter(sdf["p_max"], y)
    ax.set_title("p_max vs æ´»åŠ¨")
    ax.set_xlabel("p_max (MPa)")
    ax.set_ylabel("æ´»åŠ¨(0/1/2)")
    ax.set_yticks([0, 1, 2])
    ax.set_ylim(-0.3, 2.3)
    fig.tight_layout()
    st.pyplot(fig, use_container_width=True)

    if sdf["p_max"].nunique() > 1 and sdf["Activity"].nunique() > 1:
        corr = np.corrcoef(sdf["p_max"], sdf["Activity"])[0, 1]
        st.metric("ç›¸å…³ç³»æ•°", f"{corr:.2f}")
        if "AI_anomaly" in sdf.columns:
            st.metric("AI å¼‚å¸¸å¤©æ•°", int(sdf["AI_anomaly"].sum()))
    else:
        st.info("æ•°æ®å˜åŒ–ä¸è¶³ï¼Œæš‚æ— æ³•è®¡ç®—ç›¸å…³æ€§ã€‚å»ºè®®å¤šå½•å…¥ä¸€äº›å¤©æ•°ã€‚")

st.divider()

# ============ å†å²è®°å½• ============
st.subheader("ğŸ—‚ å†å²è®°å½•ï¼ˆæœ€è¿‘ 20 æ¡ï¼‰")
show_cols = ["date","valve_type","p_now","p_max","level","temp","psv_act","psv_weeping","HI_final","Risk_final","AI_anomaly","AI_score"]
if not set(show_cols).issubset(df.columns):
    st.dataframe(df.sort_values("date", ascending=False).head(20))
else:
    st.dataframe(df.sort_values("date", ascending=False)[show_cols].head(20))
